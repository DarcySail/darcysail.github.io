<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[关闭tmux panel无需确认]]></title>
    <url>%2F2018%2F05%2F10%2Ftmux-close-panal-without-confirm%2F</url>
    <content type="text"><![CDATA[使用tmux时经常开启关闭临时面板（panel），每次关闭时tmux都会让你确认是否真的要关闭，有些繁琐。将如下配置加入你的.tmux.conf文件来避免繁琐的确认步骤： 12bind-key &amp; kill-windowbind-key x kill-pane 重启tmux 服务，或者重新加载tmux配置文件（.tmux.conf）后生效。 参考链接：https://unix.stackexchange.com/questions/30270/tmux-disable-confirmation-prompt-on-kill-window 回答部分翻译如下： 前缀键（通常指ctrl+b）&amp;通常与confirm-before -p &quot;kill-window #W? (y/n)&quot; kill-window相绑定，confirm-before导致你需要进行确认的操作。如果你想避免确认步骤，只需要将原有的按键命令解绑，然后直接将其与kill-window重新绑定即可。 如果你想要知道你的tmux配置默认有哪些操作需要确认步骤，使用如下命令：1tmux list-keys | grep confirm-before]]></content>
      <tags>
        <tag>tmux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Using QEMU to implement micro:bit machine type emulation]]></title>
    <url>%2F2018%2F04%2F27%2FQEMU-GSoC-2018-proposal%2F</url>
    <content type="text"><![CDATA[Basic Information Name: darcy IRC nickname: darcy Programming languages (fluent): C, C++ Past open source contributions: participating write a open source technical book about ‘OpenResty’ https://github.com/moonbingbing/openresty-best-practices Sample source code, hobby projects, GitHub, etc URLs: https://github.com/DarcySail Why you are applyingThere are two reasons for participating in QEMU-GSoC: First, I’m an virtualization technology enthusiast. During my junior year at college, I’ve designed and implemented a C programming language based compiler, allowing users to directly convert native C code into a my own designed Stack-Based Instruction Set. Internally, a virtual machine to support byte-code execution is integrated into this compiler. Although this simple virtual machine prototype cannot support the full stack of virtualization technology, it’s actually the starting point for my interest in virtualization. Now, I’m pursuing my PH.D degree in University of Chinese Academy of Sciences. And I focus on low-level system software design，including virtualization technologies and AI operating systems, e.g., QEMU, Docker, etc. Thus, I want to utilize QEMU to implement the emulation of Intelligence Chip after I am familiar enough with QEMU. First, I am greatly interested in virtualization. When I was a junior, I designed and implemented a compiler that support the subset of C language, the compiler accepted C code as input, and output Stack-based Instruction Set(also designed by myself). A virtual machine was written in order to run this bytecode. Now, in my point of view, this amateur virtual machine is far from virtualization, but it’s actually the starting point for my interest in virtualization. When I came to University of Chinese Academy of Sciences as a master student, most of tasks assigned to me by my school mentor are about low-level system software. And I want to utilize QEMU to implement the emulation of Intelligence Chip after I am familiar enough with QEMU. Firstly, I am greatly interested in virtualization. When I was a junior, I designed and implemented a compiler that supports the subset of C language. The compiler accepted C code as input, and output Stack-based Instruction Set(also designed by myself). A virtual machine was written in order to run this bytecode. Now, in my point of view, this amateur virtual machine is far from virtualization, but it’s actually my starting point of the interest in virtualization. When I came to University of Chinese Academy of Sciences as a Master student, most tasks of mine assigned by my school mentor are about low-level system software. And I want to utilize QEMU to implement the emulation of Intelligence Chip after I am familiar enough with QEMU. Secondly, when I use Linux and various open source software every day, the idea of contributing to Open Source Community naturally emerge in my deep heart. QEMU-GSoC is the best practice I could take part in. Since I have read all project ideas listed in QEMU, I thought the implementation of micro:bit is not only able to satisfy my requirement of learning peripheral emulation, but also within the capability of my skill. And I have already contributed to QEMU Community by commit 4 patchs, three of them have been merged into master branch. Here are links:[1] [2] [3] [4] Summary of your understanding of the project ideaThe Project Idea of implementing micro:bit machine type provides the best testing platform for developers or kids.Besides, the implemented peripherals can be reused as modular components by future devices. What I need to do includes: Part I. Implementing ARM Cortex-M0 CPU support based on existing Cortex-M3 support in QEMU. Although the architectures are binary instructions upward compatible from Armv6-M to Armv7-M, and most(not all) binary instructions available for the Cortex-M0 can execute without modification on the Cortex-M3.[4] [5] Normally, when porting from the Cortex-M3 to the Cortex-M0, I need to change the peripheral access code, and update system features like clock speed, sleep modes, and so on. And this part of the code in the qemu architecture basically does not belong to implementiion of CPU (./target/arm), but is the work of the implementation of peripherals (./hw/arm).[6] However, what I need to do is to use QEMU’s support for cortex-m3 to implement a “true” virtual CPU rather than just using the existing cortex-m3 to implement the microbit machine functionality. Except for some functional differences in some of the instructions, the two CPUs still have some differences above features. Some programmers may write some code based on the characteristics of the processor. And some softwares should validate the existence of a feature before attempting to use it. When programmers write such code on Cortex-M0, it is assumed that these features are supported on qemu. In fact, in this case, if we directly replace cortex-m0 with cortex-m3, a series of unpredictable problems will happen. This is why we should trim unnecessary feature from Cortex-M3.[7] 1. Differences between instructionsThe Cortex-M0 contains traditional Thumb-1, not including new instructions (CBZ, CBNZ, IT) which were added in Armv7-M architecture, and a minor subset of Thumb-2 instructions (BL, DMB, DSB, ISB, MRS, MSR). The Cortex-M3 have all base Thumb-1 and Thumb-2 instructions.[8] The Cortex-M0 only has 32-bit multiply instructions with a lower-32-bit result (32bit × 32bit = lower 32bit), where as the Cortex-M3 / M4 / M7 / M33 includes additional 32-bit multiply instructions with 64-bit results (32bit × 32bit = 64bit).[8] All this unsupported instructions should be trimmed from current Cortex-M3 implementation. The specific method is to utilize the following functions provided by QEMU, using UNPREDICTABLE or UNDEFINED to replace the original instructions. 123456789101112131415161718192021222324#define ENABLE_ARCH_V6 arm_dc_feature(s, ARM_FEATURE_V6)static void disas_arm_insn(DisasContext *s, unsigned int insn)&#123; .... /* for different feature that not supported by cotex-m0(armv6); * we could raise the INVSTATE UsageFault exception. */ if (arm_dc_feature(s, ARM_FEATURE_V6)) &#123; gen_exception_insn(s, 4, EXCP_INVSTATE, syn_uncategorized(), default_exception_el(s)); return; &#125; .... /* for Instruction that not supported by cortex-m0(armv6), we * choose to UNDEF. */ if (!arm_dc_feature(s, ARM_FEATURE_NEON)) &#123; goto illegal_op; &#125;illegal_op: gen_exception_insn(s, 4, EXCP_UDEF, syn_uncategorized(), default_exception_el(s)); ....&#125; 2. Differences between featuresThe following features should be taken into consideration: ARM architecture: The Cortex-M0 implement the Armv6-M architecture, and the Cortex-M3 implements the Armv7-M architecture. Interrupts: 1 to 32 (Cortex-M0), 1 to 240 (Cortex-M3). Vector Table Offset Register: Not available for Cortex-M0. Number of watchpoint comparators: 0 to 2 (Cortex M0), 0 to 4 (Cortex-M3). Number of breakpoint comparators: 0 to 4 (Cortex M0), 0 to 8 (Cortex-M3). The performance efficiency: 0.9 DMIPS/MHz 1.25 DMIPS/MHz(this part won’t affect QEMU)[8] Except for listed above, aligned access is another important different feature. An aligned access is an operation where a word-aligned address is used for a word or multiple word access, or where a halfword-aligned address is used for a halfword access. Byte accesses are always aligned. There is no support for unaligned accesses on the Cortex-M0 processor. Any attempt to perform an unaligned memory access operation results in a HardFault exception.[9] NVIC and SCB (System Control Block) registers in the Cortex-M0 can only be accessed in word-size transfers. While some registers in the NVIC and the SCB in the Cortex-M3 are not available in the Cortex-M0. These include the Interrupt Active Status Register, the Software Trigger Interrupt Register, the Vector Table Offset Register, and some of the fault status registers.[6] The bit-band feature in the Cortex-M3 is not available in the Cortex-M0. If the bit-band alias access is used, it needs to return an error_id. In general, Cortex-M0 memory access must always be naturally aligned while Cortex-M3 doesn’t have this limit. The unsupported features should be trimmed to satisfy Cortex-M0.(refered to [code]): Part II. Implementing a “microbit” machine type. Implementing at least the 5x5 LED display, buttons, and UART. Stubbing out other devices as needed for the runtime to start successfully. Different from X86 architecture which provides port-mapped I/O, ARM architecture uses memory-mapped I/O to perform input/output (I/O) between CPU and peripheral devices. In programming of kernel module, we control peripherals by read/write I/O registers. Because of the opposite behaviors, when we try to emulate peripheral device, we should read the value of I/O register to figure out what kind of operations do users want us to achieve so that we can give feedback to users by write corresponding I/O register. In order to specify utilize QEMU to emulate peripherals in ARM architecture, we should add a QEMU data structure named “MemoryRegion” per I/O mapped-memory, then hook the “MemoryRegion” with two callback functions(one for responding reading behavior, one for responding writing behavior), as long as user’s code tries to access this “MemoryRegion”, no matter reading or writing, the right corresponding callback function will be called. And exactly in this callback function should we implement the concrete peripherals feature.[10] 123456789101112131415static uint64_t microbit_rom_read_hook(void *opaque, hwaddr offset, unsigned size)&#123; if (offset &amp; 0x1) &#123; qemu_log_mask(LOG_GUEST_ERROR, "ROM: read at bad offset 0x%x\n", (int)offset); return 0; &#125; ...&#125;static const MemoryRegionOps microbit_rom_ops = &#123; .read = microbit_rom_read, .write = microbit_rom_write, .endianness = DEVICE_NATIVE_ENDIAN,&#125;; There is no big difference between stubbing a device and actually implementing a device, both of them need to allocate a MemoryRegion, and hook the access to them, expect for stubbed device hooked with almost empty functions. Part III. Test code. In order to test the correctness of emulation code, we could use online Python(or Javascript Blocks editors) to generate specific code which controls specific peripheral. According to “nRF51 Series Reference Manual”, we check whether the generated code has written right value of right address. For example, in the emulation of LED device, we can use Python to generate “.hex” file that only controls one LED light to blink. Then we check whether the corresponding callback function has been called, and whether “.hex” code has written expected value to right I/O registers. In addition to using these official compilers, we can also use the runtime environment provided by Lancaster University, to minimize irrelevant variables. 1234567891011//This code should blink LED every 500ms.#include "mbed.h"DigitalOut led1(LED1);int main() &#123; while (true) &#123; led1 = !led1; wait(0.5); &#125;&#125; Then use the following shell command to compile the source code.1234yotta inityotta target bbc-microbit-classic-gccyotta install lancaster-university/microbityotta build The hex file we need to burn to flash rom will be found in project LED-Blink/build/bbc-microbit-classic-gcc/source and it will be called LED-Blink-combined.hex. In addition, assembly code, which directly controls peripherals, should also be able to test on baremetel virtual machine. Project plan5.15 - 5.22Implementing a micro:bit .hex ROM loader; (approximately 500 - 1000 line of c code) 5.23 - 7.11Implementing a “microbit” machine type; Stubbing out other devices as needed for the runtime to start successfully; Implementing at least the 5x5 LED display, buttons, and UART; (approximately 1000 - 1500 line of c code for these three tasks.) 6.12 - 6.13GSoC middle evaluations. 7.12 - 7.22Implementing ARM Cortex-M0 CPU support based on existing Cortex-M3 support in QEMU; (approximately 98 instructions need to be trimmed, approximately 98 * 5 = 490. Include trimming feature code, approximately 500 - 800 line of c code.) 7.10 - 7.11GSoC middle evaluations. 7.23 - 7.31Finish all basic task, completely test code, prepare and start to code other peripherals and GUI; 8.1 - 8.14Implement basic GUI. Implement other meaningful peripherals; Reference [1] http://lists.nongnu.org/archive/html/qemu-devel/2018-02/msg06778.html [2] http://lists.nongnu.org/archive/html/qemu-devel/2018-03/msg01626.html [3] http://lists.nongnu.org/archive/html/qemu-devel/2018-04/msg00899.html [4] http://lists.nongnu.org/archive/html/qemu-devel/2018-04/msg03242.html [4] ARMv6-M Architecture Reference Manual [5] ARMv7-M Architecture Reference Manual [6] The Definitive Guide to the ARM Cortex-M0 [7] Cortex-M3 Embedded Software Development [8] https://en.wikipedia.org/wiki/ARM_Cortex-M [9] STM32F0xxx Cortex-M0 programming manual [10] https://www.qemu.org/2018/02/09/understanding-qemu-devices/]]></content>
      <tags>
        <tag>QEMU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[QEMU 内部原理：整体架构和线程模型『译』]]></title>
    <url>%2F2018%2F04%2F22%2Fqemu-internals-overall-architecture%2F</url>
    <content type="text"><![CDATA[原文地址：http://blog.vmsplice.net/2011/03/qemu-internals-overall-architecture-and.htmlAuthor：Stefan HajnocziTranslator：Su Hang 这是针对开发人员的 QEMU 内部原理探析系列中的第一篇文章。它旨在分享 QEMU 工作原理的知识，并使新贡献者更容易了解 QEMU 代码。 执行 guest 代码涉及到如下任务：处理定时器、处理 I/O 请求、响应虚拟机监视器的命令，等等。要想设计一个良好的、能够解决这些问题的架构，需要安全地一次性地解决所有这些资源的分发问题。尤其是当某些请求，譬如 I/O 请求、来自用户的命令，需要大量的时间去执行的话。 一个 guest 的运行包括执行 guest 代码，处理定时器，处理 I / O 以及响应监视器命令。要想一次性地安排好所有这些事情需要一个能够以安全的方式调解资源的体系结构，而且最好不会暂停 guest 代码的执行。如果磁盘 I / O 或监视器命令需要很长时间才能完成，对于需要响应来自多个来源的事件的程序，有两种流行体系结构： 并行体系架构，将工作分解为可同时执行的进程或线程。我将称之为线程架构。 事件驱动架构，通过在一个主循环分派各个事件到与之对应的事件处理函数。这通常使用select(2)或poll(2)系列调用系列来实现，以等待多个文件描述符。 但 QEMU 实际上使用了一种将事件驱动编程与多线程相结合的混合架构。这样做是有道理的，因为事件循环不能利用多个 CPU 内核的特性，因为它只有一个执行线程。另外，有时编写专用线程来处理一个特定的任务，而不是将其集成到事件驱动的体系结构，在编程实现中更为简单。尽管如此，QEMU 的核心还是事件驱动的，大多数代码在这种环境中执行。 QEMU 的事件驱动核心事件驱动的架构以事件循环为中心，该事件循环将事件分派给处理函数。QEMU 的主要事件循环是main_loop_wait()，它执行以下任务： 等待文件描述符变为可读或可写。文件描述符起着至关重要的作用，因为无论是文件、套接字、管道还是各种其他资源都是通过文件描述符来控制的。文件描述符可以使用qemu_set_fd_handler()来添加。 运行会定时过期的定时器。定时器可以使用qemu_mod_timer()添加。 运行下半部机制 (BHs)（译者注：所谓 bottom-halves 机制，是指在允许中断的情况下，将中断处理程序延迟执行），就像立即过期的定时器一样。BH（译者注：原文中 BH 是 bottom halves 的缩写，下同）用于避免重入和溢出调用堆栈。使用qemu_bh_schedule()添加 BHs。 Linux 将一些中断处理分成两部分，第一部分是在关中断的条件下执行的，具有”原子”性，而且是中断发生以后一般要立即执行的，第二部分，就是 bottom half 了，是在开中断的条件下执行，这部分是可以延迟一段时间再做的，而且有可能将多个中断的 bottom half 合并起来一起做。 当文件描述符准备就绪，计时器到期或调度 BH 时，事件循环会调用相应该事件的回调函数。关于回调函数的执行场景，有两条简单规则： 没有其他核心代码正在同时执行，因此不需要考虑同步问题。回调函数相对于其他核心代码是顺序的，并且以原子的方式执行。在任何时候只有一个控制线程执行核心代码。 回调函数不应阻塞系统调用或进行长时间运行的运算。由于事件循环会在回调函数返回之前等待，所以其他想要被执行的事件就因此被阻塞，避免在回调中花费大量时间非常重要。打破此规则会导致 guest 虚拟机暂停并且监视器无法再响应用户。 第二条规则有时在 QEMU 的某些代码中其实是难以实现的。事实上，qemu_aio_wait()中甚至有一个嵌套事件循环等待顶层事件循环处理的事件子集。希望在未来重构代码时，可以消除这些违背了第二天规则的代码。新代码几乎从来没有合法的理由阻止，一种解决方案是使用专用工作线程来卸载长时间运行或阻塞的代码。 将特定任务分配到工作线程虽然许多 I / O 操作可以以非阻塞方式执行，但是有些系统调用没有非阻塞版本。此外，有时候长时运行的计算任务会影响 CPU，并且很难将其分解成多个小的回调函数。在这些情况下，可以谨慎地通过分配专用工作线程的方式，将这些任务移出 QEMU 核心函数。 一个工作线程的用户示例是posix-aio-compat.c，一个异步文件 I / O 实现。当 QEMU 核心代码发出 aio 请求时，该请求将被放置在一个队列中。工作线程将从队列中取出该 aio 请求并在 QEMU 核心函数之外去执行。这时就可以执行阻塞操作了，因为这些任务在自己的线程中执行并且不会阻塞 QEMU 的其余部分。通过这种方式需要注意在工作线程和 QEMU 核心函数之间执行必要的同步和通信。 另一个例子是ui/vnc-jobs-async.c，它在工作线程中进行密集的图像压缩和编码计算。 由于大多数 QEMU 核心代码不是线程安全的，所以工作线程不能调用 QEMU 核心代码代码。对于简单的实用程序——如qemu_malloc()——是线程安全的，但这算是例外而非规则。这种特性使得将工作线程事件传回 QEMU 核心函数变成了一个难题。 当工作线程需要通知 QEMU 核心代码时，会在事件循环中添加管道或qemu_eventfd()文件描述符。工作线程可以写入文件描述符，并且当文件描述符的状态变为可读时，事件循环将调用回调函数。另外，必须有一个信号来确保事件循环能够在任何情况下运行。在了解 guest 代码的执行方式后，posix-aio-compat.c使用的这种方法更加自然。 执行 guest 代码到目前为止，我们主要关注的是事件循环及其在 QEMU 中所扮演的的核心角色。但同样重要的是执行 guest 代码的能力，如果没有可执行的 guest 代码，QEMU 即使可以对事件做出响应，但这并没有太大意义。 执行 guest 代码有两种机制：微型代码生成器 (TCG) 和 KVM。TCG 使用动态二进制翻译（也称为即时 (JIT) 编译）模拟 guest。KVM 利用现代英特尔和 AMD CPU 中的硬件虚拟化扩展技术，直接在主机 CPU 上安全地执行 guest 代码。对于本文来说，在使用中实际使用哪种技术并不重要，但重要的是 TCG 和 KVM 都允许我们跳入 guest 代码并执行。 跳入 guest 代码会将执行的控制权转移给 guest。当线程正在运行 guest 代码时，它不能同时处于事件循环中，因为 guest 端对 CPU 具有（安全的）控制权。通常来说，在 guest 代码中花费的时间是有限的，因为对模拟设备寄存器的读写和其他异常处理都将导致我们离开 guest 并将控制权交还给 QEMU。但在极端情况下，guest 可以花费无限的时间去执行某段代码，而且不放弃其控制权限，在这种情况下 QEMU 会无法响应外界信息。 为了解决 guest 代码占用 QEMU 的控制线程的问题，信号被用来打破 guest 的控制权限。一个 UNIX 信号会将控制权限拉离 (yank) 当前的执行流程，并调用信号处理函数。这使 QEMU 得以采取一系列步骤脱离 guest 代码，并返回到其主循环中，其中事件循环可以有机会处理被持续推入到队列中的事件。 这样做的结果是，如果 QEMU 当前处于 guest 代码中，则可能无法立即检测到新事件。当然，大多数时候 QEMU 最终都会处理事件，但这种额外的延迟本身就是一个需要克服的性能问题。由于这个原因，定时器、I / O 完成 (completion) 和从工作线程到 QEMU 核心代码的通知 (notification)，使用信号机制来确保事件循环将立即运行。 你可能想知道事件循环与具有多个 vcpus 的 SMP guest 虚拟机之间的整体情况。在已经讨论了线程模型和执行 guest 代码之后，我们可以讨论它的整体架构。 iothread 和 non-iothread 架构传统的体系结构是单个 QEMU 线程来执行 guest 代码和事件循环。这个模型也被称为非 iothread 或!CONFIG_IOTHREAD，并且在使用./configure &amp;&amp; make编译 QEMU 源码时是默认的。QEMU 线程执行 guest 代码，直到异常或信号产生一次回退控制。然后在select(2)中以非阻塞的方式运行事件循环的一次迭代。之后，它回到 guest 代码并重复这一过程，直到 QEMU 进程退出。 如果 guest 虚拟机使用-smp 2的方式启动多个 vcpus，在这种情况下，就不会创建额外的 QEMU 线程。而是单个 QEMU 线程以多路复用的方式，在两个 vcpus 的 guest 代码和事件循环之间执行。因此，non-iothread 无法利用多核主机，并可能导致 SMP guest 机性能不佳。 请注意，尽管只有一个 QEMU 线程，但可能有零个或多个工作线程。这些线程既可能是暂时的有可能是永久的。请记住，它们执行特定的任务，而不执行 guest 代码或处理事件。我想强调一下，因为在监视 host 上面的线程，并将它们解释为 vcpu 线程时，工作线程很容易被 vcpu 线程所混淆。请记住，non-iothread 线程只有一个 QEMU 线程。 较新的体系结构是每个 vcpu 一个 QEMU 线程以及一个专用的事件循环线程。这种模式被称为 iothread 或 CONFIG_IOTHREAD，可以在构建时使用./configure --enable-io-thread启用。每个 vcpu 线程可以并行执行 guest 代码，提供真正的 SMP 支持，而 iothread 负责运行事件循环。通过全局互斥体来维护，QEMU 核心代码代码永远不会同时运行的规则是。该全局互斥体通过 vcpus 和 iothread 同步 QEMU 核心代码。大多数情况下，vcpus 将执行 guest 代码，并且不需要保存全局互斥锁。大多数情况下，select(2)中的线程被阻塞，并且不需要保持全局互斥。 请注意，TCG 不是线程安全的，因此即使在 iothread 模型下，它也是以单个 QEMU 线程来实现多路复用 vcpus。只有 KVM 可以利用 per-vcpu 线程。 结论和展望希望这有助于交流 QEMU 的整体架构 (KVM 继承）。欢迎在下面的评论中留下问题。 在将来，上面讨论到的细节可能会改变，我希望我们会默认使用 CONFIG_IOTHREAD，甚至可能会删除！CONFIG_IOTHREAD。 当 qemu 的 master 分支做出更改时，我会尝试更新此帖。]]></content>
      <tags>
        <tag>QEMU</tag>
        <tag>Translation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[了解 QEMU 设备模拟原理『译』]]></title>
    <url>%2F2018%2F04%2F22%2Funderstanding-qemu-devices%2F</url>
    <content type="text"><![CDATA[原文地址：https://www.qemu.org/2018/02/09/understanding-qemu-devices/Author：Eric BlakeTranslator：Su Hang 以下是一些可帮助新手了解 QEMU 设备实际原理的笔记： 在使用 QEMU 时，需要记住的一件事就是：以操作系统的视角来说，当其运行于我们试图模拟的裸机硬件之上时，操作系统在裸机硬件上会看到什么。大多数裸机的模拟实现仅仅是简单的内存映射，在特定地址上的软件戳（software poking) 会产生特定的边际效应（side effect）（最常见的边际效应当然是访问内存；但是内存中的其他常见区域还包括用于控制寄存器组特定的硬件，如硬盘或网卡，甚至 CPU 本身）。模拟的最终目标是允许只使用普通 ring3 内存访问（译者注：这里的普通内存访问与操作系统的 ring0 特权访问相对应）的用户空间程序来管理 guest 操作系统所期望的所有边际效应。 从实现细节上来说，一些硬件（如 x86）实际上有两个内存空间，其中 I / O 空间使用与普通内存访问（译者注：例如 mov a， b) 不同的汇编代码（译者注：这里指 in a，out a 等等 x86 架构特有汇编指令）； QEMU 必须模拟这些特殊访问。同样，许多现代 CPU 在内存地址映射范围中，也为提供了一组 CPU 本地寄存器，例如中断控制寄存器。 对于在某些特定硬件，我们通过虚拟化挂钩技术（virtualization hooks)，使得 CPU 本身可以很容易地捕获非正常存储器访问的汇编指令（那些访问 I / O 空间或 CPU 内部寄存器的指令，因此需要不同于正常存储器访问的边际效应），所以 guest 机只是执行与裸机相同的汇编指令序列，但是执行之后会导致陷入到 trap 中，让运行于用户空间的 QEMU 在对控制权返回 guest 代码之前使用普通的用户空间内存访问对指令作出反应。QEMU 通过“加速器”实现了这个功能。 虚拟化加速器（如 KVM）可以使 guest 代码运行在 QEMU 虚拟机中的速度几乎与裸机一样快。其中速度减慢的部分是由来自 guest 代码的每个 trap 都会返回至 QEMU（vmexit）执行，以处理非正常的汇编指令或内存地址引起的。除此之外，QEMU 还支持其他虚拟化加速器（例如 HAXM 或 macOS 的 Hypervisor.framework）。 QEMU 还拥有一个 TCG 加速器，该加速器在运行期（译者注：可视为一种 Just in time 技术）将 guest 汇编指令编译为相应的主机指令或调用主机帮助例程。TCG 技术虽然速度不及硬件加速，但它允许跨硬件模拟，例如在 x86 上运行 ARM 代码。 接下来要弄清楚的是当操作系统访问各种硬件资源时都发生了些什么。例如，大多数操作系统都附带了管理 IDE 磁盘的驱动程序 - 驱动程序仅仅是一种软件，它被编程为对特定的内存映射子集（译者注：简单来说就是某一片内存区域）（IDE 总线所在的任何位置）发出特定的 I / O 请求，与不同的硬件相绑定）。当 IDE 控制器硬件接收到这些 I / O 请求时，它会执行相应的操作（通过 DMA 传输或其他硬件操作）将数据从内存复制到永久存储器（写入磁盘）或从永久存储器复制到内存（从磁盘读取）。 当我们购买一个包含未初始化磁盘的裸机硬件时，我们安装使用操作系统中相应驱动程序，对 IDE 硬件映射到内存的部分进行访问，然后将磁盘格式化为一系列分区和文件系统。 那么，QEMU 如何模拟这个功能呢？在 QEMU 提供给 guest 代码的内存映射中，它在与裸机相同的地址处（译者注：具体地址得查阅相应的硬件手册）模拟 IDE 磁盘。当 guest 操作系统驱动程序向 IDE 控制寄存器发出特定的内存写入操作以便将数据从内存复制到永久存储器时，QEMU 加速器会陷入该内存区域（译者注：通过 Hook 技术实现），并将请求传递到 QEMU IDE 控制器设备模型。设备模型会解析 I / O 请求，并通过发出主机系统调用来模拟它们。这一系列行为的结果是 guest 内存被复制到 host 机器的存储中。 在 host 端，模拟永久存储的最简单方法是将主机文件系统中的文件视为不包含任何结构信息的原始数据（raw data）（也就是说，host 文件中的偏移量与 guest 驱动程序访问的磁盘偏移量，以 1：1 比例映射）. 但 QEMU 实际上能够将许多不同主机格式（raw， qcow2，qed， vhdx，…）和协议（文件系统，块设备， NBD， Ceph，gluster 等）的任意组合粘合在一起作为后端，然后在 QEMU 对硬件的模拟中绑定到提供服务的 guest 设备。 因此，当您告诉 QEMU 使用主机 qcow2 文件时，guest 虚拟机不必对 qcow2 文件格式有任何了解，仅仅只需要 guest 的驱动程序执行与裸机相同的寄存器读写操作，从而触发 vmexits 进入 QEMU 代码，然后 QEMU 将这些访问映射到 qcow2 文件的相应偏移量中来进行读写。在首次安装 guest 虚拟机时，所有 guest 虚拟机都会看到一个空白未初始化的线性磁盘（无论该磁盘在主机中是线性的——如原始数据（raw format）；还是针对随机访问进行了优化，如 qcow2 格式）；guest 操作系统决定如何划分其硬盘并在其上安装文件系统，而 QEMU 不关心 guest 代码正在使用什么文件系统，只关心原始磁盘（raw disk）I / O 寄存器控制序列的模式。 接下来要意识到的是，模拟 IDE 并不总是最高效的。每次 guest 试图写入控制寄存器时，都必须经过特殊处理，并且 vmexits 会减慢模拟速度。当然，不同的硬件模型在虚拟化时具有不同的性能特征。然而，一般来说，对真实硬件最有效实现方法并不一定适用于其在虚拟化之中的实现，直到最近，硬件并没有被设计成当通过 QEMU 等软件进行模拟时运行得更快。因此，QEMU 包含专为此目的而设计的半虚拟化设备（paravirtualized device）。 在 QEMU 这里的“半虚拟化”的含义，与半虚拟化的原始含义：“通过 guest 和主机之间的合作实现虚拟化”略有不同。QEMU 开发人员已经制定了一套硬件寄存器规范，并规定了这些寄存器的行为，这些寄存器旨在尽可能减少 vmexits 的数量，同时仍然完成硬盘必须做的事情，即实现 guest 内存和持久存储设备之间的传输。这个规范被称为 virtio；使用它需要在 guest 虚拟机中安装 virtio 驱动程序。尽管不存在与 virtio 具有相同的寄存器布局的物理设备，但其理念是相通的：virtio 磁盘的行为类似于内存映射寄存器组，guest 操作系统驱动程序知道将哪些操作硬件的寄存器值的写入该存储体，以使数据被复制进出其他 guest 内存。virtio 中的大部分加速功能都是通过它的如下设计实现的：guest 虚拟机为其大部分硬件命令序列设置了一部分常规内存，只需启动一个寄存器即可告知 QEMU 读取命令序列（较少的映射寄存器访问意味着更少的 vmexits），通过握手机制（handshaking）来保证 QEMU 处理这些命令序列时 guest 端驱动程序在不会改变正常内存。 顺带一提，就像最新的硬件在实现虚拟化时效率十分高效一样，virtio 也在演进为通过硬件来实现变得更加高效，当然不会以牺牲模拟或虚拟化的性能来达到此目的。因此，将来你也可能会偶然发现实现了物理 virtio 的高性能设备。 同样，许多操作系统都支持多个网卡，一个常见的例子就是 PCI 总线上的 e1000 板卡。在裸机上，操作系统将检测 PCI 空间，当看到具有 e1000 签名的寄存器组被填充时，就加载驱动程序，然后该驱动程序知道要写入的寄存器命令序列，以便让硬件传输网络流量。因此，QEMU 拥有一台 e1000 设备——作为众多网卡模拟实现之一——映射到同一个内存区域（译者注：这里的 guest 内存区域指的是 host 上面的用户内存区域），而真正的 guest 内存区域将裸露在被模拟的裸机内存上。 其次，e1000 寄存器布局往往需要大量的寄存器写入（并因此需要 vmexits）来满足硬件的工作需求，因此 QEMU 开发人员添加了 virtio-net 卡（PCI 硬件规范，尽管现在还没有实现它的真实物理硬件），因此在 guest 操作系统中安装 virtio-net 驱动程序可以最大限度地减少 vmexits 的数量，同时还能获得与发送网络流量的相同边际效应。如果您告诉 QEMU 使用 virtio-net 卡启动 guest 虚拟机，则 guest 虚拟机操作系统将探测 PCI 空间，并使用 virtio-net 签名查看一系列寄存器，并加载适用于任何其他 PCI 硬件的适当驱动程序。 总结一下，尽管 QEMU 最初是为了虚拟化 guest 操作系统而模拟硬件内存映射，但事实证明，最快的虚拟化还是取决于虚拟硬件：具有特定边际效应的寄存器内存映射的效率没有任何物理硬件能够匹敌。所有的硬件设备虚拟化实际上意味着运行一组特定的汇编指令（guest 操作系统）来处理映射到内存中的地址，以产生一组特定的边际效应，其中 QEMU 仅仅是一个提供内存映射，并模仿在裸机硬件上执行这些 guest 指令时所获得的相同边际效应的用户空间应用程序。]]></content>
      <tags>
        <tag>QEMU</tag>
        <tag>Translation</tag>
      </tags>
  </entry>
</search>
